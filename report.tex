\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}

\title{Artist Identification	\\  a comparison between AlexNet, GoogLeNet and ResNeXt}


\author{
  Mattia Bottaro \\
  Dipartimento  di Matematica\\
  Università di Padova \\
  \texttt{mattia.bottaro@studenti.unipd.it} \\
  %% examples of more authors
   \And
  Mauro Carlin \\
Dipartimento  di Matematica\\
Università di Padova \\
\texttt{mauro.carlin@studenti.unipd.it} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
\maketitle

\begin{abstract}
	In this essay we present our work for the project of the Cognitive Services course.
	The problem we face is the artist identification task, that is given the image of a painting, being able to recognize its author.\\
	In order to resolve this task, we have exploit some differents Convolutional Neural Networks (CNNs) that comes with \textit{Pytorch} library. Such networks have been trained in according to two distinct approaches: \textit{1.} training them from scratch or  \textit{2.} exploit pre-trained models using transfer learning technique. We used the \textit{Google Cloud Plataform} to train and evaluate our models.\\
	What we have achieved is a set of results which are in line with  state-of-the-art (\cite{ArtistIdCNN406}) ..., confirming that CNNs are suitable to solve this type of task.
\end{abstract}


% keywords can be removed
\keywords{Convolutional Neural Networks \and Artist Identification \and CNNs \and ResNeXt \and GoogLeNet \and AlexNet \and Transfer Learning}


\section{Introduction}
Artist identification is a task regarding recognition of the painter who depicted a certain painting, given an image of it.\\
It's still nowadays a difficult problem to solve for the following reasons: \textit{1.} there are not many contributions yet and these rely on the latest models of deep learning (e.g. CNNs). \textit{2.} The available datasets are not as large as those used by models that solve more common tasks such as object detection or face recognition. \textit{3.} An artist's style can change a lot through his works, or it could be influenced by other painters. \\For example, it is well known that Paul Cézanne and Camille Pissarro, who have spent a period of their lives in close contact, have produced some works of similar style.\\
This type of task is still done by art experts and contributions to this type of problem can help and lead to \textit{1.} the development of automatic fake artifact detection and \textit{2.} automatic cataloguing of artworks.\\

We used three different CNNs: AlexNet (2012), GoogLeNet (2014) and ResNeXt (2016). For each of them, we have established two different ways of training: from scratch and with transfer learning  upon pre-trained version of such CNNs. Then we have observed and compared their performance. From our experiment we have obtained ... RISULTATI 82\% accuracy.\\

The rest of the essay is structured as follows: In section 2 we discuss (\textbf{METTI I REF}) similarities and differences between previous works and ours. In section 3 we explain which dataset we have used, how it was formed and which preprocessing and data augmentation techniques we have exploited. In section 4 we exhibit the CNNs' architectures and how we have trained them. In section 5 we show some details regarding the \textit{GCloud Compute Engine}'s configuration, the metrics used to assess the goodness of the models and the detailed results of this experiment. Finally, in section 6 we draw some conclusion and we outline some possibile future works which rely on our result.


\section{Related Works}

\paragraph{Art Painting Identification using Convolutional Neural Network (2017)}
\url{https://www.ripublication.com/ijaer17/ijaerv12n4_17.pdf}\\
CNN for art painting identification.\\ Hanno applicato diversi tipi di distorsione perchè volevano simulare il riconoscimento di opere i TV, film o simili. Pensa a questa cosa in ottica di protezione del copyright. Questo ha portato alla data augmentation. "sliding window scheme [2-4] to extract the region of interest".
\textbf{Architettura rete}: Nel training trasforma le immagini in 256x256 grayscale e poi scala i pixel value in -1,+1.  Inizializza i pesi a caso secondo una gaussiana "The ReLU nonlinearity is applied to the output of every convolutional and
fully-connected layer; Spatial pooling is carried out by maxpooling layers; Adam Optimizer is used to minimize the loss." Tre tipi di architettura sfruttando tali moduli. La prima ispirata ad AlexNet, la seconda a VGG e la terza una versione ridotta della seconda. Loro quindi creano architetture, noi no.
Mostrano le differenze di prestazione sulla terza architettura al variare dell'inizializzazione dei pesi/bias e dell'optimezir/learning rate (table 2 e 3). Questo paper sembra avere un approccio sperimentale migliore del nostro. Dovremmo prenderne spunto.

\paragraph{Large-scale Classification of Fine-Art Paintings:
	Learning The Right Metric on The Right Feature (2015)}
\url{https://arxiv.org/pdf/1505.00855.pdf}\\
Vanno a riconoscere stile, genere e artista di un quadro. Elencano una serie di features oggetto di analisi: "space, texture, form, shape, color, tone and line are used. Other principles include movement, unity, harmony, variety, balance, contrast, proportion, and pattern. To
this might be added physical attributes, like brush strokes as well as subject matter and
other descriptive concepts For the task of computer analyses of art, researchers have engineered and investigated various visual features3
that encode some of these artistic concepts, in particular
brush strokes and color, which are encoded as low-level features such as texture statistics and color histograms (e.g. [19, 20]). Color and texture are highly prone to variations during the digitization of paintings; color is also affected by a painting’s age". Sostengono però che ingegnerizzare tutte queste features porterebbe ad un processo confusionario.  Le cnn permettono il "learning" delle features dai dati invece di pre-elaborare le features prima menzionate.\\ Loro comunque seguono una terza strategia: vanno a studiare lo stato dell'arte per vari elementi visivi. Poi usano metric learning  per vari tipi di previsioni: stile, genere e artista. Questo lo fanno in ottica di un sistema di raccomandazione. Tre metodologie: metric learning, feature fusion, metric-fusion.

\paragraph{The Rijksmuseum Challenge:
	Museum-Centered Visual Recognition (2014)}
\url{https://staff.fnwi.uva.nl/t.e.j.mensink/publications/mensink14icmr.pdf} bah.. di interessante hanno che stimano l'anno di creazione.

\paragraph{Recognizing Image Style (2014)}
\url{https://arxiv.org/pdf/1311.3715.pdf} \\
Qui operano su foto reali e quadri per predirne lo stile. "Distinct visual styles are apparent in art, cinematography, advertising, and have become extremely popular in amateur photography, with apps like Instagram leading the way". Sottolineano che "the distinctions between, say, Rococo versus pre-Rafaelite style are less relevant to modern photography and design." e anche che tali stili non sono in mutua esclusione. "This leads to one
conclusion of our work: mid-level features derived from object datasets are generic for style
recognition, and superior to hand-tuned features."

\paragraph{Classification of Artistic Styles using Binarized
	Features Derived from a Deep Neural Network ($\geq$ 2014)}\url{http://courses.cs.tau.ac.il/~wolf/papers/genrestyle.pdf}\\


\section{Dataset}

\paragraph{Overview}\mbox{}\\
La prima cosa necessaria per allenare una cnn per questi task è un grande dataset di quadri di differenti artisti. Il dataset da noi utilizzato è preso da \cite{ArtGANDataset} che non è altro che un sottoinsieme del dataset Wikiart (cit link a wikiart). Si tratta di un dataset contenete circa 19k immagini di 23 artisti differenti , provenienti da epoche diverse fra loro, i quali hanno stili diversi fra loro, ma influenzati fra loro. Le immagini differiscono in dimensioni e forma.  Ci sono dei file .csv che contengono le label di ogni quadro suddividendo i quadri per  autore .Per avere un dataset bilanciato, abbiamo, per ogni artista, selezionato randomly 450 quadri.
L'organizzazione di \cite{ArtGANDataset} non presentava un test-set. Abbiamo quindi suddiviso i quadri in subset di train, validation e test con uno split 80-10-10, ottenengo quindi 360 quadri per il training, 45 per test e 45 per validation per ogni artista. In totale il numero complessivo di quadri è 10350.
Inoltre \cite{ArtGANDataset} presentava alcuni quadri in più subset, cosa da noi evitata in quanto ciò non porterebbe ad una corretta valutazione delle performance.
\paragraph{Preprocessing and Data augmentation}\mbox{}\\
Per dare in input le immagini alle cnn è necessario che esse abbiano una certa forma e dimensione. Per ogni immagine prendiamo un crop di 224x224 e zero-centered (sottrarre la media) e normalization e utilizzando media e deviazioni standard per ogni channel (trattandosi di immagini RGB) red, green e blue. \\
Scrivere a cosa serve la data aug. Abbiamo utilizzato delle tecniche di data augmentation quali: per ogni immagine, prima di darla in input alla rete nella fase di training, abbiamo preso un crop 224x224 in una posizione casuale dell'immagine e flippato orizzontalmente con una prob del 50\%. Queste tecniche sono usate in task di visual recognition per aumentare il dataset e ridurre la possibilità di incorrere in overfitting.
Inoltre, per questo specifico task, ogni punto del quadro ha contenuto informativo sullo stile dell'autore.
\textbf{STUDIARSI COSA VUOL DIRE FARE NORMALIZATION (ZERO CENTER) E PERCHÈ È UTILE}.

\section{Method}

\paragraph{CNNs from scratch}

\paragraph{CNNs with Transfer Learning}


\section{Experiments}

\paragraph{Setup}

\paragraph{Implementation Details}

\paragraph{Evaluation Metrics}

\paragraph{Results}




\section{Conclusion}

%%% Comment out this section when you \bibliography{references} is enabled.
\begin{thebibliography}{1}
	
	\bibitem{ArtistIdCNN406}
	Nitin Viswanathan.
	\newblock Artist Identification with Convolutional Neural Networks. \newblock 2017
	
	\bibitem{ArtGANDataset}
	Un qualche nome... \newblock
	\url{https://github.com/cs-chan/ArtGAN/tree/master/WikiArt Dataset}
	
\end{thebibliography}


\end{document}

\end{document}