\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}

\title{Artist Identification	\\  A comparison between AlexNet, GoogLeNet and ResNeXt}


\author{
  Mattia Bottaro \\
  Dipartimento  di Matematica\\
  Università di Padova \\
  \texttt{mattia.bottaro@studenti.unipd.it} \\
  %% examples of more authors
   \And
  Mauro Carlin \\
Dipartimento  di Matematica\\
Università di Padova \\
\texttt{mauro.carlin@studenti.unipd.it} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
\maketitle

\begin{abstract}
	\textit{In this essay we present our work for the project of the Cognitive Services course.
	The problem we face is the artist identification task, that is being able to recognize the author of a painting, given an image of it.\\
	In order to resolve this task, we have exploited some differents Convolutional Neural Networks (CNNs) that come with \textit{Pytorch} library. Such networks have been trained in according to two distinct approaches: training them from scratch or exploiting pre-trained models using transfer learning technique. We used the \textit{Google Cloud Plataform} to train and evaluate our models.\\
	What we have achieved is a set of results which are in line with the  state-of-the-art, confirming that CNNs are suitable to solve this type of task.}
\end{abstract}


% keywords can be removed
\keywords{Convolutional Neural Networks \and Artist Identification \and CNNs \and ResNeXt \and GoogLeNet \and AlexNet \and Transfer Learning}


\section{Introduction}
Artist identification is a task regarding recognition of the painter who depicted a certain painting, given an image of it.\\
It's still nowadays a difficult problem to solve for the following reasons:
\begin{itemize}
	\item there are not many contributions yet and these rely on the latest models of deep learning (e.g. CNNs). 
	\item The available datasets are not as large as those used by models which solve more common tasks such as object detection or face recognition.
	\item An artist's style can change a lot through his works, or it could be influenced by other painters. For example, it is well known that Paul Cézanne and Camille Pissarro, who have spent a period of their lives together, have produced some works of similar style.
\end{itemize}
This type of task is still done by art experts and contributions to this type of problem can help and lead to the development of automatic fake artifact detection and automatic cataloguing of artworks.\\
We used three different CNNs: AlexNet (2012), GoogLeNet (2014) and ResNeXt (2016). For each of them, we have established two different ways of training: from scratch and with transfer learning  upon pre-trained version of such CNNs. Then we have observed and compared their performance. From our experiment we have obtained 83.768\% accuracy.\\


The rest of the essay is structured as follows: In section \ref{relwor} we discuss  similarities and differences between previous works and ours. In section \ref{dataset} we explain which dataset we have used, how it was formed and which preprocessing and data augmentation techniques we have exploited. In section\ref{method} we exhibit the CNNs' architectures and how we have trained them. In section \ref{experiments} we show some details regarding the \textit{GCloud Compute Engine}'s configuration, the metrics used to assess the goodness of the models and the detailed results of this experiment. Finally, in section \ref{conclusions} we draw some conclusion and we outline some possibile future works which rely on our result.


\section{Related Works}\label{relwor}

In this section we show some previous works related to ours. In addition to defining the references our experiment, the following should further convince the reader of present-day difficulty in achieving good precision in artist identification.\\
Recently CNNs have become widespread, this is due to the good performance and results obtained in this kind of task. In fact, we can distinguish the contributions to this task between those that come before the spreading of the CNNs, and thus do not use them, and those that instead benefit from it.\\
In our problem, the features that characterize an artist's style can be many and difficult to engineer, such as texture, shape, color, tone, variety, proportion, pattern and brush strokes.\\
Instead, it is well known that CNNs are able to learn those features that characterize an image, without having to identify and engineer a set of characterizing features.\\
In works prior to CNNs, some famous approaches of detection features are exploited, such as Scale Invariant Feature Transforms (SIFT) and Histograms of oriented gradients (HOG) (\cite{Saleh2015}, \cite{mensink2014}, \cite{lombardi05}, \cite{jou2011}). These works have in common the use of an SVM 1-vs-rest classifier, except \cite{jou2011} which uses both SVM 1-vs-rest and Naïve Bayes classifier.\\ However, \cite{lombardi05} and \cite{jou2011} face the problem of style recognition, which is different than artist identification.\\
In addition, some of these perform on small or not so heterogenous datasets, such as \cite{mensink2014} which uses the artwork of a single museum, or \cite{jou2011} which focuses on only 5 artists. Instead, in our work we focus on recognizing 23 different artists, and for each of them we take the same number of artifacts (\cite{ArtGANDataset}). \\

One of the results achieved in \cite{hong2017} shows the actual improvement of performance in the use of CNNs up to 13.6\% more than SIFT, HOG or similar.  This work aims to detect artwork that violates copyright terms in television programs, TV series, movies or similar scenarios. They use different techniques to distort the images on their dataset, which would not be suitable for our context. They experiment with three different CNNs inspired by AlexNet and VGG, then they trained them from scratch with a weights' initialization according to a Gaussian distribution. In our work, instead, we use pre-existing CNNs. \cite{hong2017} is one of the few works which does not use SVM as classifier, but 3 Fully Connected Layers, and the last of them is a Soft-Max layer.\\
Other works like \cite{Bar2014} and \cite{razavian2014} use a CNN to generate features, then use an SVM 1-vs-rest classifier on top of it.
\cite{ArtistIdCNN406} exploit one of the most recent CNNs: ResNet-18 (\cite{resnet}). It is an ancestor of ResNeXt (\cite{resneXt}), one of the CNNs used in our experiment. As in our work, also in \cite{ArtistIdCNN406} either training from scratch and training through transfer learning are studied.
\\

In the latest years, the number of CNNs for visual recognition task is growing, as well as their contributions in the field of computer vision. What is missing is a performance comparison between the latter models in the field of artist identification and, more generally, in art-recognition tasks. This comparison is the purpose of our work.


\paragraph{Notes}
\subparagraph{Artist Identification with Convolutional Neural Networks (2017)}
\url{http://cs231n.stanford.edu/reports/2017/pdfs/406.pdf}\\
\begin{itemize}
	\item usano CNN e non sift/hog/simili
	\item è il related work più simile al nostro
	\item il contesto è quello del labelling automatico di quadri. Noi diremo anche il detection di fake.
	\item Utilizza resnet-18, quindi uno dei latest model. Fa pretrained e from scratch.
	\item il dataset è preso da kaggle, però basato su wikiart. Di 2300 artisti, si focalizzano solo su 57 (quelli con più di 300 quadri ognuno).
\end{itemize}
\subparagraph{Art Painting Identification using Convolutional Neural Network (2017)}
\url{https://www.ripublication.com/ijaer17/ijaerv12n4_17.pdf}\\
CNN for art painting identification.\\ Hanno applicato diversi tipi di distorsione perchè volevano simulare il riconoscimento di opere i TV, film o simili. Pensa a questa cosa in ottica di protezione del copyright. Questo ha portato alla data augmentation. "sliding window scheme [2-4] to extract the region of interest".
\textbf{Architettura rete}: Nel training trasforma le immagini in 256x256 grayscale e poi scala i pixel value in -1,+1.  Inizializza i pesi a caso secondo una gaussiana "The ReLU nonlinearity is applied to the output of every convolutional and
fully-connected layer; Spatial pooling is carried out by maxpooling layers; Adam Optimizer is used to minimize the loss." Tre tipi di architettura sfruttando tali moduli. La prima ispirata ad AlexNet, la seconda a VGG e la terza una versione ridotta della seconda. Loro quindi creano architetture, noi no.
Mostrano le differenze di prestazione sulla terza architettura al variare dell'inizializzazione dei pesi/bias e dell'optimezir/learning rate (table 2 e 3). Questo paper sembra avere un approccio sperimentale migliore del nostro. Dovremmo prenderne spunto. Loro non fanno transfer learning, noi sì.

\begin{itemize}
	\item usano CNN e mostrano che sono meglio di SIFT come risultato.
	\item il dataset è preso prendendo immagini da google e poi data augmentation con varie distortion
	\item questo perchè loro si collocano nel contesto di riconoscere artefatti in film/tv per riconoscere eventuali violazioni di copyright.
	\item progettano i moduli e li combinano in 3 modi diversi per ottenere 3 reti diverse ispirate a AlexNet  VGG
	
\end{itemize}

\subparagraph{Large-scale Classification of Fine-Art Paintings:
	Learning The Right Metric on The Right Feature (2015)}
\url{https://arxiv.org/pdf/1505.00855.pdf}\\
Vanno a riconoscere stile, genere e artista di un quadro. Elencano una serie di features oggetto di analisi: "space, texture, form, shape, color, tone and line are used. Other principles include movement, unity, harmony, variety, balance, contrast, proportion, and pattern. To
this might be added physical attributes, like brush strokes as well as subject matter and
other descriptive concepts For the task of computer analyses of art, researchers have engineered and investigated various visual features3
that encode some of these artistic concepts, in particular
brush strokes and color, which are encoded as low-level features such as texture statistics and color histograms (e.g. [19, 20]). Color and texture are highly prone to variations during the digitization of paintings; color is also affected by a painting’s age". Sostengono però che ingegnerizzare tutte queste features porterebbe ad un processo confusionario.  Le cnn permettono il "learning" delle features dai dati invece di pre-elaborare le features prima menzionate.\\ Loro comunque seguono una terza strategia: vanno a studiare lo stato dell'arte per vari elementi visivi. Poi usano metric learning  per vari tipi di previsioni: stile, genere e artista. Questo lo fanno in ottica di un sistema di raccomandazione. Tre metodologie: metric learning, feature fusion, metric-fusion.

\begin{itemize}
	\item dicono che fare le feature esplicite è complesso. Dicono che le cnn le estraggono da sole. Ma loro seguono la terza strada: estraggono prima le visual features e poi metric learning.
	\item wikiart painting dataset
\end{itemize}

\subparagraph{The Rijksmuseum Challenge:
	Museum-Centered Visual Recognition (2014)}
\url{https://staff.fnwi.uva.nl/t.e.j.mensink/publications/mensink14icmr.pdf} bah.. di interessante hanno che stimano l'anno di creazione.

\begin{itemize}
	\item 1vsRest SVM
	\item dataset solo Rijksmuseum in Amsterdam.
	
\end{itemize}

\subparagraph{Recognizing Image Style (2014)}
\url{https://arxiv.org/pdf/1311.3715.pdf} \\
Qui operano su foto reali e quadri per predirne lo stile. "Distinct visual styles are apparent in art, cinematography, advertising, and have become extremely popular in amateur photography, with apps like Instagram leading the way". Sottolineano che "the distinctions between, say, Rococo versus pre-Rafaelite style are less relevant to modern photography and design." e anche che tali stili non sono in mutua esclusione. "This leads to one
conclusion of our work: mid-level features derived from object datasets are generic for style
recognition, and superior to hand-tuned features."

\subparagraph{Classification of Artistic Styles using Binarized
	Features Derived from a Deep Neural Network (2014)}\url{http://courses.cs.tau.ac.il/~wolf/papers/genrestyle.pdf}\\
\begin{itemize}
	\item stanno sull'identificazione dello stile
	\item usan CNN per generare feature e poi classificano con SVM 1vsRest
	\item è una sorta di transfer learning: Decaf
	\item dataset è subset di wikiart
\end{itemize}

\subparagraph{Cosa fare per ogni related work}

Parlare di SIFT-GIST-HOG per rappresentare feature. Chiaramente per i paper che ne fanno utlizzo. Noi utilizziamo CNN. Il dataset che utilizzano. Noi lo bilanciamo, alcuni no, altri utilizzano quadri di solo un museo. Il contesto nel quale vrrebero calarsi. Se utilizzano reti, come sono formate e che classificatore utilizzano. \\
Tutti mirano più allo stile che al pittore. Solo il più recente non usa più SVM ma Fully connected (da verificare). Dire che nessuno, tranne 406, fanno transfer learning. Questo prova che si tratta ancora di un task poco affrontato (aperto), e che i recenti contributi nel campo delle CNNs possono/sembrano essere determinanti nel miglioramento delle prestazioni. Nei vari approcci affrontati, pare che le cnns siano la strada migliore. C'è la fiducia di poter superare il livello umano in futuro (magari in future works).


\section{Dataset}\label{dataset}


\paragraph{Overview}\mbox{}\\
La prima cosa necessaria per allenare una cnn per questi task è un grande dataset di quadri di differenti artisti. Il dataset da noi utilizzato è preso da \cite{ArtGANDataset} che non è altro che un sottoinsieme del dataset Wikiart (cit link a wikiart). Si tratta di un dataset contenete circa 19k immagini di 23 artisti differenti , provenienti da epoche diverse fra loro, i quali hanno stili diversi fra loro, ma influenzati fra loro. Le immagini differiscono in dimensioni e forma.  Ci sono dei file .csv che contengono le label di ogni quadro suddividendo i quadri per  autore .Per avere un dataset bilanciato, abbiamo, per ogni artista, selezionato randomly 450 quadri.
L'organizzazione di \cite{ArtGANDataset} non presentava un test-set. Abbiamo quindi suddiviso i quadri in subset di train, validation e test con uno split 80-10-10, ottenengo quindi 360 quadri per il training, 45 per test e 45 per validation per ogni artista. In totale il numero complessivo di quadri è 10350.
Inoltre \cite{ArtGANDataset} presentava alcuni quadri in più subset, cosa da noi evitata in quanto ciò non porterebbe ad una corretta valutazione delle performance.
\paragraph{Preprocessing and Data augmentation}\mbox{}\\
Per dare in input le immagini alle cnn è necessario che esse abbiano una certa forma e dimensione. Per ogni immagine prendiamo un crop di 224x224 e zero-centered (sottrarre la media) e normalization e utilizzando media e deviazioni standard per ogni channel (trattandosi di immagini RGB) red, green e blue. \\
Scrivere a cosa serve la data aug. Abbiamo utilizzato delle tecniche di data augmentation quali: per ogni immagine, prima di darla in input alla rete nella fase di training, abbiamo preso un crop 224x224 in una posizione casuale dell'immagine e flippato orizzontalmente con una prob del 50\%. Queste tecniche sono usate in task di visual recognition per aumentare il dataset e ridurre la possibilità di incorrere in overfitting.
Inoltre, per questo specifico task, ogni punto del quadro ha contenuto informativo sullo stile dell'autore.
\textbf{STUDIARSI COSA VUOL DIRE FARE NORMALIZATION (ZERO CENTER) E PERCHÈ È UTILE}.

\section{Method}\label{method}
abbiamo considerato tre reti cnn ossia, alexnet, googlenet e resnext.
Ad ogni rete abbiamo dato in input un'immagine RGB 3x224x224 e dato in output un valore di cofidenza per tutti e 23 gli artisti, prendendo il massimo come risultato della classificazione. 
Per ognuna delle reti abbiamo utilizzato un classifier softmax con cross entropy loss.
\begin{equation}
L_{i}=-\log \left(\frac{e^{f_{y_{i}}}}{\sum_{j} e^{f_{j}}}\right)
\end{equation}
Spiegare prendendo spunto.

Prima di tutto abbiamo allenanato le reti from scratch, in modo da cercare di imparare le features solamente per il compito di artisti identification.\\
Successivamente partendo dalle stesse architetture usando i pesi pretreinate sul ImageNet Dataset, per valutare se le features estratte per l'image recognition possono essere un buon punto di partenza per l'artist identification. Infatti ci aspettiamo che per determinati stili, come il Realism o reinassence, tali features possono essere utili, cosa non vera per cubismo, minimalismo, astrattismo.
\paragraph{AlexNet}\mbox{}\\
AlexNet was the winning entry in ILSVRC 2012. It solves the problem of image classification where the input is an image of one of 1000 different classes (e.g. cats, dogs etc.) and the output is a vector of 1000 numbers, achieving a top-5 error of 15,8\%.
L'architettura è caratterizzata da 8 strati, 5 convolutional e 3 fully connected, con max pooling e ReLu come funzione di attivazione. RIFERIMENTO A IMMAGINE
Un'altra caratteristica di ALexnet è l'utilizzo della tecnica di dropout, introdotta nello stesso anno in \cite{dropout}, per ridurre l'overfitting. 
In dropout, a neuron is dropped from the network with a probability of 0.5. When a neuron is dropped, it does not contribute to either forward or backward propagation. 
As a result, the learnt weight parameters are more robust and do not get overfitted easily. \\

MOTIVAZIONE SCELTA


\paragraph{GoogLeNet}\mbox{}\\
È stato il vincitore di ILSVRC 2014. It achieves 6.67\% top-5 error on ImageNet.
L'architettura è caratterizzata da 22 layer, con alcune novità per quanto riguarda gli strati fully connected, la gestione del problema del vanish del gradiente, e l'introduzione di un cossiddetto inception module.\\
Another interesting addition to the architecture is to change the second last fully-connected layer with an average pooling layer. This layer spatially averages the feature map, converting 7x7x1024 input to 1x1x1024, reducing the computation and the number of parameters, by a factor of 49. This average pooling layer is finally followed by a normal fully-connected layer with 1000 neurons (and 1024x1000 parameters), for the 1000 ImageNet classes.

During training, to address the vanishing gradient problem, special extra structures are added to the network (these are removed during testing). These are
auxiliary classifiers attached to intermediate layers. All the losses from each
classifier gets added up, taking contribution from the auxiliary classifier lower
than the main one, during training. The gradient from the main classifier which
would have otherwise become very small, and thus slowing training, by time it
reached the lower initial layers, receives gradient from the auxiliary classifiers
and thus the net gradient becomes big enough to allow training to progress.

\subparagraph{Inception Module}
Inception Modules are used in GoogLeNet to allow for more efficient computation through a dimensionality reduction with stacked 1x1 convolutions. The modules were designed to solve the problem of computational expense, as well as overfitting, among other issues. The solution, in short, is to take multiple kernel filter sizes within the CNN, and rather than stacking them sequentially, ordering them to operate on the same level. 

As a neural net deals with a vast array of images, with wide variation in the featured image content, also known as the salient parts, they need to be designed appropriately. The most simplified version of an inception module works by performing a convolution on an input with not one, but three different sizes of filters (1x1, 3x3, 5x5). Also, max pooling is performed. Then, the resulting outputs are concatenated and sent to the next layer.
A method to reduce the number of computation is dimensionality reduction. This involves convolutions with 1x1 filters before convolutions with bigger filters.

\paragraph{ResNeXt}
ResNeXt was the first runner up in ILSVRC 2016, achieving 3.03\% top-5 error rate, superando la precisione umana.
Si tratta di una cnn residual, ossia presenta i cosiddetti residual block, (spiegazione residual).
The model name, ResNeXt, contains Next. It means the next dimension, on top of the ResNet, ossia la CNN vincitrice del  ILSVRC 2015. \\
This next dimension is called the “cardinality” dimension.
SPIEGARE NUOVO BLOCCO CON RIFERIMENTO A CARDINALITA

Noi abbiamo utilizzato 

\section{Experiments}\label{experiments}

\paragraph{Setup}

\paragraph{Implementation Details}

\paragraph{Evaluation Metrics}

\paragraph{Results}




\section{Conclusions}\label{conclusions}

%%% Comment out this section when you \bibliography{references} is enabled.
\begin{thebibliography}{1}
	
	\bibitem{hong2017}
	Yiyu Hong, Jongweon Kim, \newblock  Art Painting Identification using Convolutional Neural Network, \newblock International Journal of Applied Engineering Research, \newblock 2017
	
	\bibitem{Saleh2015}
	B. Saleh and A. M. Elgammal.\newblock  Large-scale classification
	of fine-art paintings: Learning the right metric on the right
	feature. \newblock CoRR, abs/1505.00855, 2015.
	\bibitem{Bar2014}
	W. L. Bar Y., Levy N. Classification of artistic styles using binarized features derived from a deep neural network.
	ECCV 2014.
	
	\bibitem{mensink2014}
	T. Mensink and J. van Gemert. \newblock The rijksmuseum challenge:
	Museum-centered visual recognition. \newblock 2014
	
	
	\bibitem{ArtistIdCNN406}
	Nitin Viswanathan, Standford University,
	\newblock Artist Identification with Convolutional Neural Networks, \newblock 2017
	
	\bibitem{ArtGANDataset}
	Un qualche nome... \newblock
	\url{https://github.com/cs-chan/ArtGAN/tree/master/WikiArt Dataset}
	
	\bibitem{Lij2012}
	E. H. J. Li, L. Yao and J. Z. Wang. \newblock Rhythmic brushstrokes
	distinguish van gogh from his contemporaries: Findings via
	automated brushstroke extractions. IEEE Trans. Pattern
	Anal. Mach. Intell, \newblock 2012.
		
	\bibitem{lombardi05}
	T. E. Lombardi. \newblock The classification of style in fine-art painting. ETD Collection for Pace University, \newblock 2005.
	
	\bibitem{jou2011}
	J. Jou and S. Agrawal. Artist identification for renaissance
	paintings, 2011.
	\bibitem{razavian2014}
	A. H. S. J. C. S. Sharif Razavian, A. Cnn features off-theshelf: An astounding baseline for recognition, 2014.
	
	\bibitem{resnet}
	Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. Microsoft Research. 
	Deep Residual Learning for Image Recognition. 2015
	
	\bibitem{resneXt}
	Saining Xie, Ross Girshick, Piotr Dollar, Zhuowen Tu, Kaiming He. UC San Diego - Facebook AI Research. Aggregated Residual Transformations for Deep Neural Networks, 2017.
	
	\bibitem{googlenet}
	Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich. Going Deeper with Convolutions. 2014
	
	\bibitem{alexnet}
	Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton. ImageNet Classification with Deep Convolutional
	Neural Networks. 2012
	
	\bibitem{dropout}
	G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever and R. R. Salakhutdinov.
	Improving neural networks by preventing co-adaptation of feature detectors. 2012
	
	
\end{thebibliography}


\end{document}

\end{document}